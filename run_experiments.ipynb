{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNS46nlx9lDASjPfYIWnGF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bateikoEd/Actor-Critic-and-Deep-Deterministic-Policy-Gradient-in-the-2022/blob/dev/run_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n"
      ],
      "metadata": {
        "id": "hIICcIZ3yf12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ],
      "metadata": {
        "id": "X9aEtlr8ya8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npP3tLxHtOx3",
        "outputId": "7280f1ca-3f01-4e24-ea7d-eb703a36da85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL\")\n",
        "\n",
        "import itertools\n",
        "\n",
        "\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "BhPgvozwtl7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path for reading preprocesed data and saving reusults\n",
        "## if you use colab\n",
        "# drive.mount('/content/drive')\n",
        "# path_saving_models = '/content/drive/MyDrive/test/' \n",
        "# path_data_dicrectory = '/content/drive/MyDrive/test/'\n",
        "\n",
        "# if you use local machine\n",
        "path_saving_models = 'saving_results/'\n",
        "path_data_dicrectory = 'preprocessed_data/'\n",
        "\n",
        "SUFIX_AGENT = '_AGNT'\n",
        "SUFIX_ENV = '_ENV'\n",
        "\n",
        "processed_full = pd.read_csv(path_data_dicrectory + 'qqq.csv').iloc[:, 1:]\n",
        "BASELINE_TICKET = \"^NDX\"\n",
        "\n",
        "TRAIN_START_DATE = '2022-01-01'\n",
        "TRAIN_END_DATE = '2022-06-01'\n",
        "TRADE_START_DATE = '2022-06-01'\n",
        "TRADE_END_DATE = '2022-09-28'\n",
        "\n",
        "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
        "print(len(train))\n",
        "print(len(trade))\n",
        "\n",
        "print(INDICATORS)\n",
        "\n",
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nltVExk_tgYB",
        "outputId": "1ebdf98f-4fb8-49e8-f3a8-cb5fc01e6c4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8240\n",
            "6480\n",
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
            "Stock Dimension: 80, State Space: 801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set envirinment"
      ],
      "metadata": {
        "id": "0vTHhq1ZtpYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 100000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}\n",
        "\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
        "\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "\n",
        "dict_params_env = dict()\n",
        "\n",
        "for param, values in env_kwargs.items():\n",
        "  if param in ['num_stock_shares', 'buy_cost_pct', 'sell_cost_pct']:\n",
        "    dict_params_env[param] = env_kwargs[param][0]\n",
        "\n",
        "  else:\n",
        "    dict_params_env[param] = env_kwargs[param]"
      ],
      "metadata": {
        "id": "plYqrp7vtsE2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set agent parameters\n"
      ],
      "metadata": {
        "id": "Hae71BUbuB11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AGENT_NAME = 'sac' # sac, ppo, ddpg, td3, a2c\n",
        "\n",
        "total_timesteps = 100000\n",
        "\n",
        "PARAMS = {}\n",
        "if AGENT_NAME == 'sac':\n",
        "\n",
        "  PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "  }\n",
        "elif AGENT_NAME == 'ppo':\n",
        "\n",
        "  PARAMS = {\n",
        "      \"n_steps\": 2048,\n",
        "      \"ent_coef\": 0.01,\n",
        "      \"learning_rate\": 0.00025,\n",
        "      \"batch_size\": 128,\n",
        "  }\n",
        "elif AGENT_NAME == 'td3':  \n",
        "  PARAMS = {\"batch_size\": 100, \n",
        "                \"buffer_size\": 1000000, \n",
        "                \"learning_rate\": 0.001}\n",
        "else:\n",
        "  PARAMS = dict()\n",
        "\n",
        "list_params = ['batch_size', 'buffer_size', \n",
        "               'learning_rate', 'learning_starts',\n",
        "               'ent_coef', 'n_steps']\n",
        "\n",
        "dict_paramas_agent_main = defaultdict(float)\n",
        "\n",
        "for param in list_params:\n",
        "  dict_paramas_agent_main[param] = PARAMS.get(param, -1)\n",
        "\n",
        "dict_paramas_agent_main['name'] = AGENT_NAME\n",
        "dict_paramas_agent_main['timestemps'] = total_timesteps\n",
        "\n",
        "dict_config = dict()\n",
        "\n",
        "# add params for agent\n",
        "for param, value in dict_paramas_agent_main.items():\n",
        "  dict_config[param + SUFIX_AGENT] = value\n",
        "\n",
        "# add params for env\n",
        "for param, value in dict_params_env.items():\n",
        "  dict_config[param + SUFIX_ENV] = value\n",
        "\n",
        "\n",
        "# initialize agent\n",
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "if len(PARAMS) > 0:\n",
        "  model = agent.get_model(AGENT_NAME, model_kwargs = PARAMS)\n",
        "else:\n",
        "  model = agent.get_model(AGENT_NAME)\n",
        "\n",
        "dict_config['TRAIN_START_DATE'] = TRAIN_START_DATE\n",
        "dict_config['TRAIN_END_DATE'] = TRAIN_END_DATE\n",
        "dict_config['TRADE_START_DATE'] = TRADE_START_DATE\n",
        "dict_config['TRADE_END_DATE'] = TRADE_END_DATE\n",
        "\n",
        "print(f\"config:\\t{dict_config}\")\n",
        "print(f\"dict_params_env:\\t{dict_params_env}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_2LuMlYuEM8",
        "outputId": "bfb6ffaa-c1e5-4308-bc53-cc35c18d8607"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "config:\t{'batch_size_AGNT': 128, 'buffer_size_AGNT': 100000, 'learning_rate_AGNT': 0.0001, 'learning_starts_AGNT': 100, 'ent_coef_AGNT': 'auto_0.1', 'n_steps_AGNT': -1, 'name_AGNT': 'sac', 'timestemps_AGNT': 10, 'hmax_ENV': 100, 'initial_amount_ENV': 100000, 'num_stock_shares_ENV': 0, 'buy_cost_pct_ENV': 0.001, 'sell_cost_pct_ENV': 0.001, 'state_space_ENV': 801, 'stock_dim_ENV': 80, 'tech_indicator_list_ENV': ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma'], 'action_space_ENV': 80, 'reward_scaling_ENV': 0.0001, 'TRAIN_START_DATE': '2022-01-01', 'TRAIN_END_DATE': '2022-06-01', 'TRADE_START_DATE': '2022-06-01', 'TRADE_END_DATE': '2022-09-28'}\n",
            "dict_params_env:\t{'hmax': 100, 'initial_amount': 100000, 'num_stock_shares': 0, 'buy_cost_pct': 0.001, 'sell_cost_pct': 0.001, 'state_space': 801, 'stock_dim': 80, 'tech_indicator_list': ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma'], 'action_space': 80, 'reward_scaling': 0.0001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment"
      ],
      "metadata": {
        "id": "JmieiugoucX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER = '_' + str(5)\n",
        "\n",
        "\n",
        "RUN_NAME = AGENT_NAME + BASELINE_TICKET + NUMBER\n",
        "\n",
        "\n",
        "\n",
        "# TRAINING\n",
        "\n",
        "print(\"Training ...\")\n",
        "trained_model = agent.train_model(model=model, \n",
        "                            tb_log_name=AGENT_NAME,\n",
        "                            total_timesteps=total_timesteps) \n",
        "\n",
        "# ------------------------- traiding\n",
        "\n",
        "# Set turbulence threshold\n",
        "print(\"Processing ...\")\n",
        "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
        "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
        "\n",
        "# back testing\n",
        "turbulence_threshold = insample_risk_indicator.vix.quantile(0.996)\n",
        "risk_indicator_col = 'vix'\n",
        "\n",
        "# create traiding env\n",
        "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = turbulence_threshold, risk_indicator_col=risk_indicator_col, **env_kwargs)\n",
        "\n",
        "# --------- define model\n",
        "print(\"Predictions ...\")\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_model, environment = e_trade_gym)\n",
        "\n",
        "# - savign for creating images \n",
        "df_account_value.to_csv( path_saving_models + 'df_accnt_val' + RUN_NAME \\\n",
        "                        + BASELINE_TICKET + '.csv', \\\n",
        "                        index=False)\n",
        "\n",
        "# - savign for creating images \n",
        "df_actions.to_csv( path_saving_models + 'df_actions' + RUN_NAME \\\n",
        "                        + BASELINE_TICKET + '.csv', \\\n",
        "                        index=False)\n",
        "# ------------------------\n",
        "\n",
        "# calculate backtest \n",
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "\n",
        "# ---- create dict for backtesting\n",
        "dict_trading_backtest = dict()\n",
        "\n",
        "for i, metric_value in enumerate(perf_stats_all.values):\n",
        "  metric_name = perf_stats_all.index[i]\n",
        "  metric_name = '_'.join(metric_name.lower().split())\n",
        "\n",
        "  dict_trading_backtest[metric_name] = metric_value[0]\n",
        "\n",
        "# -------------------- \n",
        "\n",
        "# calculate baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline( \\\n",
        "        ticker=BASELINE_TICKET, \\\n",
        "        start = df_account_value.loc[0,'date'],\\\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
        "\n",
        "# ------ create dict for baseline\n",
        "dict_trading_baseline = dict()\n",
        "dict_trading_baseline['ticker'] = BASELINE_TICKET\n",
        "\n",
        "for i, metric_value in enumerate(stats.values):\n",
        "  metric_name = stats.index[i]\n",
        "  metric_name = '_'.join(metric_name.lower().split())\n",
        "\n",
        "  dict_trading_baseline[metric_name] = metric_value\n",
        "\n",
        "# -----------------------\n",
        "\n",
        "dict_trading_baseline = dict((metric + '_bs', value) for metric, value in dict_trading_baseline.items())\n",
        "dict_trading_backtest = dict((metric + '_bc', value) for metric, value in dict_trading_backtest.items())\n",
        "\n",
        "\n",
        "# print plots\n",
        "\n",
        "print(\"==============Compare to Ticker===========\")\n",
        "%matplotlib inline\n",
        "backtest_plot(df_account_value, \\\n",
        "            baseline_ticker = BASELINE_TICKET, \\\n",
        "            baseline_start = df_account_value.loc[0,'date'],\\\n",
        "            baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
      ],
      "metadata": {
        "id": "n103M3KVue7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}